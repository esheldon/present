\documentclass{beamer}

\usepackage{beamerthemesplit}
\usepackage{verbatim}
\usepackage[normalem]{ulem}

\usepackage{xcolor}

\usepackage{hyperref}

\definecolor{gold}{rgb}{1.,0.84,0.}
\definecolor{brightred}{rgb}{1.,0.4,0.4}
\definecolor{mygray}{RGB}{200,200,200}
\definecolor{lightsteelblue}{RGB}{176,196,222}
\definecolor{lightskyblue}{RGB}{135,206,250}
\definecolor{cadetblue}{RGB}{95,158,160}

\usetheme{default}
\usecolortheme{mule}

\usefonttheme{serif}

%\DeclareGraphicsExtensions{.pdf,.png,.jpg}

\newcommand{\mcal}{\textsc{metacalibration}}
\newcommand{\Mcal}{\textsc{Metacalibration}}

\expandafter\def\expandafter\insertshorttitle\expandafter{%
      \insertshorttitle\hfill%
        \insertframenumber\,/\,\inserttotalframenumber}

% suppress navigation bar
\beamertemplatenavigationsymbolsempty
\setbeamertemplate{footline}{}


\title{Weak Lensing Algorithms and Lessons Learned from Precursor Experiments}
\author{Erin Sheldon}
\institute{Brookhaven National Laboratory}
\date{Match 19, 2020}
%

\begin{document}
\setbeamertemplate{background canvas}[vertical shading][bottom=mgray,top=mblack]

\setbeamerfont*{itemize/enumerate body}{size=\Large}
\setbeamerfont*{itemize/enumerate subbody}{parent=itemize/enumerate body}
\setbeamerfont*{itemize/enumerate subsubbody}{parent=itemize/enumerate body}


%
\frame
{

    % \frametitle{Introduction}

    {\huge The charge from the organizing committee: }
    \newline

    \begin{quote}
    ``...to speak on algorithms and pipelines you have developed or
    used in other surveys, lessons learnt, particularly any unexpected
    challenges you have encountered, and to highlight what you would do
    differently or additionally with LSST in order to maximize scientific
    return.''
    \end{quote}


}

\frame
{

    \frametitle{Outline}

    %\setbeamerfont*{itemize/enumerate body}{size=\large}

    \begin{itemize}

        \item The challenge
        \item Lessons from precursor surveys
        \item What we in DESC need for weak lensing shear
        \item What we in DESC are doing for weak lensing shear

    \end{itemize}

}

\frame
{
    \frametitle{The Challenge}

    \setbeamerfont*{itemize/enumerate body}{size=\large}

    \begin{itemize}

        \item We have set the bar extremely high.  We want to make full use of the
            great data we will receive from the Rubin Observatory.

        \item For example, for the weak lensing probe we need to recover the
            signal with an accuracy of about 0.1\%.  At the time of writing,
            the most accurate measurements in the literature are at the 1-2\%
            level.

        \item Other probes also have very tight requirements.

        \item In order to meet these goals we must put forth a huge effort, and
            work with great discipline.

    \end{itemize}

}

\frame
{
    \frametitle{Precursor Survey Work}

    \begin{itemize}

        \item SDSS shear pipeline development and lensing analysis

        \item BOSS target selection framework

        \item DES shear pipeline development and lensing analysis

        \item What did I/we learn from all this, and how are we implementing
            that knowledge for LSST?

    \end{itemize}

}

\frame
{
    \frametitle{Lesson: Identify the Critical Problems that are Unsolved}

    \begin{itemize}

        \item There are unsolved problems which {\em must be solved} if we are to succeed.

        \item Dedicate as many resources as possible to solving these problems

            \begin{itemize}
                \item This will require some {\em convincing}
            \end{itemize}

        \item Spend as little time as possible on solved problems (more on this later)

    \end{itemize}

}

\frame
{
    \frametitle{Example from My Experience}

    \setbeamerfont*{itemize/enumerate body}{size=\large}

    \begin{itemize}

        \item DES was proposed in about 2003 with weak lensing (WL) as a primary
            probe.  We thought we would soon have a WL method that
            would meet our needs.

        \item Weak lensing measurement is still not a fully solved problem in
            2020.  Only recently have candidate algorithms been introduced that
            can work in principle.

        % \item There are hundreds of people in the project whose science depends
        %     directly on the weak lensing calibration.

        \item  Over the years there have been at most a few persons full time
            sustained effort (FTE) spent on this problem within DES, at a given
            time.  More typically it has been about 1.0, shared between a few
            people, as most people have multiple duties.

            %At times this effort has been {\em less than one}.

    \end{itemize}

}
\frame
{
    \frametitle{Effort on Unsolved Problems in LSST}

    \setbeamerfont*{itemize/enumerate body}{size=\large}

    \begin{itemize}

        \item The situation is very similar in LSST right now, with about 1.5
            FTE on WL calibration.

        \item We have good candidates (metacalibration, BFD) but limited effort.

        \item If we fail we must fall back to {\em calibration from simulations}.
            %which as far as I know would be unprecedented for a major physics experiment.

    \end{itemize}

}



\frame
{
    \frametitle{Lesson: Use Existing Solutions if they are Good Enough}

    \setbeamerfont*{itemize/enumerate body}{size=\large}

    \begin{itemize}

        \item These solutions might not fit perfectly, we may have to bend
            them out of shape or adapt to their idiosyncrasies

        \item In most cases it will save so much time and frustration that it
            is worth it

        \item There is often more than one solution available, especially in
            cases where the software industry has already solved the problem.

        \item There are unsolved problems which {\em must be solved} if we are
            to succeed.  We must put our effort towards those problems.

    \end{itemize}

}

\frame
{
    \frametitle{Lesson: Aggressively test algorithms with validation simulations}

    \setbeamerfont*{itemize/enumerate body}{size=\large}

    \begin{itemize}

        \item Build up simulations in such a way that we can toggle all the
            relevant features, independently if possible

        \item Turn on features one at a time until we a) find a problem which we
            will try to fix or b) we reach full planned simulation complexity
            and the algorithm provides acceptable accuracy.

        \item Each test must be much more precise than the expected precision
            of the measurements we plan to make on real data.  For example, we
            want to be confident there is no bias with at least 99.7\%
            confidence.  This is necessary but can be resource intensive.

    \end{itemize}

}

\frame
{
    \frametitle{Lesson: Use best software practices, e.g. Unit Tests}

    \begin{itemize}

        \item Validation tests are in addition to unit tests, which may also be
            partly simulation based

        \item Use extensive unit tests and continuous integration (e.g. circleci
            on github)

    \end{itemize}

}

\frame
{

    \frametitle{Lesson: Confirmation bias is even more relevant for validation
    simulations than for real data analysis }

    \begin{itemize}

        \item The process is by definition iterative, we find problems and fix
            them

        \item We have many opportunities to fool ourselves:  We tend to stop when we
            measure no bias and move on to the next test.

        \item Always quote least 99.7\% confidence regions.  We will run
            thousands of tests and 2 sigma fluctuations will be seen regularly.

    \end{itemize}

}

\frame
{

    \frametitle{There May be Some Remaining Bias in the Validation Sims}

    \begin{itemize}

        \item There may be some remaining biases which we need to correct.

        \item How should we approach these corrections?

    \end{itemize}

}


\frame
{

    \frametitle{Lesson: Calibration simulations are harder than good data analysis}

    \setbeamerfont*{itemize/enumerate body}{size=\small}

    \begin{itemize}

        \item Often with data analysis, we don't need to understand everything that
            we measured, or how it is measured.

            \begin{itemize}

                \item We don't do photometric calibration by simulating the
                    instrument.  We calibrate to reference sources in a regime
                    where the machine response is linear.

            \end{itemize}

        \item If we want to use a sim for estimating a large correction factor,
            we must know what we are doing. We need to understand what we put
            into the sim and it must match the real world very well.

        \item Therefore we should put as much effort as possible into developing
            algorithms that require small corrections.

            \begin{itemize}
    
                \item If the correction is 1\% we will be less sensitive to the
                    errors in the simulations than if the correction is 10\%.

            \end{itemize}

    \end{itemize}

}


\end{document}
